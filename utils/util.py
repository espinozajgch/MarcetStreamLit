import streamlit as st
import pandas as pd
from fpdf import FPDF
import numpy as np
import requests
from datetime import datetime
from utils.pdf import PDF
from scipy.stats import percentileofscore
from functools import reduce
import unicodedata

def get_ttl():
    if st.session_state.get("reload_data", False):
        default_reload_time = "0m"  # Forzar recarga
        st.session_state["reload_data"] = False  # Resetear flag despuÃ©s de la recarga
    else:
        default_reload_time = "360m"  # Usar cachÃ© normalmente

    return default_reload_time

def get_usuarios(conn):
    df = conn.read(worksheet="USUARIOS", ttl=get_ttl())
    return df

def get_test(conn):
    df = conn.read(worksheet="TEST", ttl=get_ttl())
    return df

def convertir_fecha_segura(valor):
    try:
        return pd.to_datetime(valor, format="%d/%m/%Y").date()
    except Exception:
        print(f"âŒ Fecha invÃ¡lida: {valor}")
        return None
    
def get_player_data(conn):
    #st.cache_data.clear()
    df = conn.read(worksheet="DATOS", ttl=get_ttl())
    #st.dataframe(df)
    hoy = datetime.today()

    for col in df.select_dtypes(include=["object", "string"]):
        df[col] = df[col].str.strip()

    # Convertir a tipo datetime (asegura formato dÃ­a/mes/aÃ±o)
    
    #df["FECHA DE NACIMIENTO"] = pd.to_datetime(df["FECHA DE NACIMIENTO"], format="%d/%m/%Y")
    df["FECHA DE NACIMIENTO"] = df["FECHA DE NACIMIENTO"].apply(convertir_fecha_segura)
    #df["EDAD"] = df["FECHA DE NACIMIENTO"].apply(lambda x: hoy.year - x.year - ((hoy.month, hoy.day) < (x.month, x.day)))    
    df["EDAD"] = df["FECHA DE NACIMIENTO"].apply(lambda x: hoy.year - x.year - ((hoy.month, hoy.day) < (x.month, x.day)) if x else None)

    #df["FECHA DE NACIMIENTO"] = df["FECHA DE NACIMIENTO"].dt.strftime('%d/%m/%Y').astype(str)

    df["FECHA DE NACIMIENTO"] = df["FECHA DE NACIMIENTO"].apply(lambda x: x.strftime('%d/%m/%Y') if isinstance(x, pd.Timestamp) else None
)
    df["NACIONALIDAD"] = df["NACIONALIDAD"].astype(str).str.replace(",", ".", regex=False).str.strip()
    df['NACIONALIDAD'] = df['NACIONALIDAD'].apply(quitar_acentos)

    df.drop_duplicates(subset=["ID"], keep="first")
    
    df["FECHA REGISTRO"] = pd.to_datetime(df["FECHA REGISTRO"], format="%d/%m/%Y")
    df = df.sort_values(by=["FECHA REGISTRO"], ascending=False).reset_index(drop=True)
    df["FECHA REGISTRO"] = df["FECHA REGISTRO"].dt.strftime('%d/%m/%Y').astype(str)
    df = df.astype({ "ID": str }) 
    df = df.astype({ "JUGADOR": str }) 

    # Eliminar filas donde ID es NaN, 0 o "nan"
    #df = df[df["ID"].notnull() &
    #(df["ID"].astype(str) != "0") &
    #(df["ID"].astype(str).str.lower() != "nan")]

    return df

def getData(conn):
    df_datos = get_player_data(conn)

    df_an = get_test_data(conn,'ANTROPOMETRIA')
    df_ag = get_test_data(conn,'AGILIDAD')
    df_sp = get_test_data(conn,'SPRINT')
    df_cmj = get_test_data(conn,'CMJ')
    df_yoyo = get_test_data(conn,'YO-YO')
    df_rsa = get_test_data(conn,'RSA')

    df_checkin = get_test_data(conn,'CHECK-IN')

    columnas_comunes = ['FECHA REGISTRO', 'ID', 'CATEGORIA', 'EQUIPO']
    df_data_test = unir_dataframes([df_an, df_ag, df_sp, df_cmj, df_yoyo, df_rsa], columnas_comunes)

    df_data_test["CATEGORIA"] = df_data_test["CATEGORIA"].str.strip()
    df_data_test["EQUIPO"] = df_data_test["EQUIPO"].str.strip()

    columnas_excluidas = ["FECHA REGISTRO", "ID", "JUGADOR" ,"CATEGORIA", "EQUIPO", "TEST"]
    columnas_estructura = get_dataframe_columns(df_data_test)
   
    # Eliminar columnas excluidas
    columnas_filtradas = [col for col in columnas_estructura if col not in columnas_excluidas]

    df_data_test = limpiar_columnas_numericas(df_data_test, columnas_filtradas)
    df_checkin = limpiar_columnas_numericas(df_checkin, columnas_filtradas)

    #st.text("Datos de los tests")
    #st.dataframe(columnas_filtradas)
    return df_datos, df_data_test, df_checkin

def unir_dataframes(dfs, columnas_comunes, metodo='outer'):
    """
    Une una lista de DataFrames basÃ¡ndose en columnas comunes.

    Args:
        dfs (list): Lista de DataFrames a unir.
        columnas_comunes (list): Columnas comunes para hacer el merge.
        metodo (str): Tipo de uniÃ³n ('outer' para no perder datos, 'inner' para intersecciÃ³n).

    Returns:
        DataFrame: Un DataFrame combinado con columnas comunes al inicio.
    """
    if not dfs:
        raise ValueError("La lista de DataFrames estÃ¡ vacÃ­a.")
    
    dfs = [df.drop_duplicates(subset=columnas_comunes) for df in dfs]

    # Verifica que todos los DataFrames contengan las columnas comunes
    for df in dfs:
        for col in columnas_comunes:
            if col not in df.columns:
                raise ValueError(f"La columna '{col}' no existe en uno de los DataFrames.")
    
    # Merge secuencial de todos los DataFrames
    df_final = reduce(lambda left, right: pd.merge(left, right, on=columnas_comunes, how=metodo), dfs)
    
    # Eliminar filas donde TODAS las columnas NO comunes son NaN
    columnas_no_comunes = [col for col in df_final.columns if col not in columnas_comunes]
    df_final = df_final.dropna(subset=columnas_no_comunes, how='all')

    # Reordenar columnas: comunes primero
    columnas_ordenadas = columnas_comunes + [col for col in df_final.columns if col not in columnas_comunes]
    df_final = df_final[columnas_ordenadas]
    
    return df_final

def es_numerico(val):
    try:
        return isinstance(val, (int, float)) and not pd.isna(val)
    except:
        return False
    
def get_test_data(conn, hoja):
    df = conn.read(worksheet=hoja, ttl=get_ttl())
    df = df.reset_index(drop=True)  # Reinicia los Ã­ndices

    if "ID" in df.columns:
        df = df.astype({"ID": str})  # o ajusta a tus columnas especÃ­ficas
    else:
        df.columns = df.iloc[0]  # Usa la primera fila como nombres de columna
        df = df[1:]  # Elimina la fila de encabezado original
        df = df.reset_index(drop=True)
        
        mask = df.applymap(es_numerico)
        df = df[mask.any(axis=1)]
        
        # âœ… Reemplazo sin advertencia futura
        df = df.replace("None", 0)
        df = df.fillna(0)
        df = df.infer_objects(copy=False)
       
        df["CATEGORIA"] = "Check in"
        df["JUGADOR"] = df["JUGADOR"].str.upper()

    return df

def get_dataframe_columns(dataframe):
    dataframe_columns = dataframe.columns.tolist()
    return dataframe_columns

def getJoinedDataFrame(df_datos, df_data_test):

    # Verificar si alguno de los DataFrames estÃ¡ vacÃ­o
    if df_datos.empty or df_data_test.empty:
        return pd.DataFrame()  # Retornar DataFrame vacÃ­o si alguno de los dos estÃ¡ vacÃ­o

    columnas_excluidas = ["FECHA REGISTRO", "ID", "CATEGORIA", "EQUIPO", "GENERO"]
    columnas_estructura = get_dataframe_columns(df_data_test)

    # Eliminar columnas excluidas
    columnas_filtradas = [col for col in columnas_estructura if col not in columnas_excluidas]

    # Asegurarse de insertar el nombre completo en la posiciÃ³n 2 si falta
    columna_nombre = "JUGADOR" 
    columna_genero = "GENERO" 
    
    # Si hay datos ya existentes, mapear nombres desde datos_jugadores
    if not df_data_test.empty:
        # Eliminar registros cuyo ID no estÃ¡ en df_datos
        df_data_test = df_data_test[df_data_test["ID"].isin(df_datos["ID"])]

        # Asegurar que la columna de nombres estÃ© presente
        if columna_nombre not in df_data_test.columns:
            df_data_test.insert(2, columna_nombre, None)

        if columna_genero not in df_data_test.columns:
            df_data_test.insert(3, columna_genero, None)

        # Mapear nombres desde df_datos
        id_a_nombre = df_datos.set_index("ID")["JUGADOR"].to_dict()
        id_a_genero = df_datos.set_index("ID")["GENERO"].to_dict()
        df_data_test[columna_nombre] = df_data_test["ID"].map(id_a_nombre)
        df_data_test[columna_genero] = df_data_test["ID"].map(id_a_genero)

        # Eliminar registros ya existentes segÃºn ID
        #datos_jugadores = datos_jugadores[~datos_jugadores["ID"].isin(df_data_test["ID"])]

    #st.dataframe(df_data_test)
    # Realizar el merge asegurando que las claves de uniÃ³n existen en ambos DataFrames
    common_columns = ['ID', 'JUGADOR', 'CATEGORIA', 'EQUIPO']
    if not all(col in df_datos.columns and col in df_data_test.columns for col in common_columns):
        return pd.DataFrame()  # Si faltan columnas clave, retornar vacÃ­o

    #df_unido = pd.merge(df_datos, df_data_test, on=common_columns, how="inner")

    # Verificar si el DataFrame unido quedÃ³ vacÃ­o
    #if df_unido.empty:
    #return df_data_test

    # Convertir la columna de fecha asegurando el formato correcto
    df_data_test["FECHA REGISTRO"] = pd.to_datetime(df_data_test["FECHA REGISTRO"], errors='coerce', dayfirst=True)

    # # Eliminar filas con fechas invÃ¡lidas
    # df_unido = df_unido.dropna(subset=["FECHA REGISTRO"])

    # # Extraer aÃ±o y mes
    df_data_test["anio"] = df_data_test["FECHA REGISTRO"].dt.year.astype(str)
    df_data_test["mes"] = df_data_test["FECHA REGISTRO"].dt.month.astype(str)

    # # Ordenar por fecha de mÃ¡s reciente a mÃ¡s antigua
    df_data_test = df_data_test.sort_values(by="FECHA REGISTRO", ascending=False)

    # # Convertir la fecha a string en formato dd/mm/yyyy
    df_data_test["FECHA REGISTRO"] = df_data_test["FECHA REGISTRO"].dt.strftime('%d/%m/%Y').astype(str)

    # # Aplicar transformaciÃ³n solo a esas columnas
    #df_data_test[columnas_filtradas] = df_data_test[columnas_filtradas].apply(lambda col: col.astype(str).str.replace(r"[,-]", ".", regex=True).astype(float))
    df_data_test = limpiar_columnas_numericas(df_data_test, columnas_filtradas)

    # # Reemplazar valores nulos o 'None' por 0
    df_data_test = df_data_test.fillna(0).replace("None", 0)

    # Eliminar filas donde todos los valores son 0
    #df_data_test = df_data_test.loc[:, (df_data_test != 0).any(axis=0)]
    df_data_test = df_data_test.astype({ "JUGADOR": str })  # o ajusta a tus columnas especÃ­ficas

    return df_data_test

def limpiar_columnas_numericas(df, columnas_filtradas):
    for col in columnas_filtradas:
        # Reemplaza comas y guiones por puntos, convierte a numÃ©rico (NaN si falla)
        df[col] = (
            df[col]
            .astype(str)
            .str.replace(r"[,-]", ".", regex=True)
            .pipe(pd.to_numeric, errors="coerce")
        )
    
    return df

def columnas_sin_datos_utiles(df, columnas_excluidas=None, mostrar_alerta=False, mensaje="â— No hay datos Ãºtiles en las columnas seleccionadas."):
    """
    Verifica si todas las celdas (excepto columnas excluidas) son NaN, None o 0.

    Args:
        df (pd.DataFrame): DataFrame a validar.
        columnas_excluidas (list): Lista de columnas a ignorar.
        mostrar_alerta (bool): Si True, muestra advertencia en Streamlit.
        mensaje (str): Texto de advertencia a mostrar.

    Returns:
        bool: True si todas las celdas Ãºtiles son NaN, None o 0. False en caso contrario.
    """
    if df.empty:
        return True

    columnas_estructura = get_dataframe_columns(df)

    # Si no se pasa una lista, usar lista vacÃ­a
    columnas_excluidas = columnas_excluidas or []

    # Eliminar columnas excluidas
    columnas_filtradas = [col for col in columnas_estructura if col not in columnas_excluidas]

    if not columnas_filtradas:
        return True  # Nada que validar

    try:
        todos_vacios_o_ceros = (
            df[columnas_filtradas]
            .map(lambda x: pd.isna(x) or x == 0)
            .all()
            .all()
        )

        if todos_vacios_o_ceros and mostrar_alerta:
            st.warning(mensaje)

        return todos_vacios_o_ceros

    except KeyError as e:
        st.error(f"âŒ Columnas no encontradas: {e}")
        return True

def get_metricas_por_test(df_estructura, tests_seleccionados):
    """
    Devuelve una lista Ãºnica de mÃ©tricas asociadas a los tests seleccionados,
    segÃºn la estructura del DataFrame.

    Args:
        df_estructura (pd.DataFrame): DataFrame con columnas como tipos de test,
                                      y filas como mÃ©tricas asociadas.
        tests_seleccionados (list): Lista de nombres de tests seleccionados (columnas del DataFrame).

    Returns:
        list: Lista Ãºnica de mÃ©tricas (valores no nulos) asociadas a los tests.
    """
    if not tests_seleccionados:
        return []

    metricas = []

    for test in tests_seleccionados:
        if test in df_estructura.columns:
            metricas.extend(df_estructura[test].dropna().tolist())

    # ğŸ”¥ Eliminar duplicados respetando el orden de apariciÃ³n
    metricas_unicas = list(dict.fromkeys(metricas))

    return metricas_unicas

def get_new(datos_jugadores, df_existente, columnas_datos, fecha=None):
    """
    Genera un nuevo DataFrame con la estructura de 'df_existente',
    agregando registros faltantes por combinaciÃ³n (JUGADOR + CATEGORIA + FECHA REGISTRO),
    y asignando correctamente la fecha si se especifica.

    Siempre ordena por FECHA REGISTRO de menor a mayor
    y coloca la columna JUGADOR justo despuÃ©s de ID.

    Args:
        datos_jugadores (pd.DataFrame): Nuevos registros a insertar.
        df_existente (pd.DataFrame): DataFrame original con estructura base.
        columnas_datos (list): Columnas clave a mantener desde los datos de origen.
        fecha (str, opcional): Fecha Ãºnica para asignar a nuevos registros. Formato: 'dd/mm/yyyy'.

    Returns:
        pd.DataFrame: DataFrame combinado y ordenado por 'FECHA REGISTRO' y 'JUGADOR'.
    """
    
    columnas_estructura = get_dataframe_columns(df_existente)
    if "JUGADOR" not in columnas_estructura:
        columnas_estructura.insert(2, "JUGADOR")

    # === AÃ±adir JUGADOR a df_existente si falta ===
    if "JUGADOR" not in df_existente.columns and "ID" in df_existente.columns:
        if "ID" in datos_jugadores.columns and "JUGADOR" in datos_jugadores.columns:
            id_to_nombre = datos_jugadores.set_index("ID")["JUGADOR"].to_dict()
            df_existente["JUGADOR"] = df_existente["ID"].map(id_to_nombre)

    # === AÃ±adir CATEGORIA a df_existente si falta ===
    if "CATEGORIA" not in df_existente.columns and "ID" in df_existente.columns:
        if "ID" in datos_jugadores.columns and "CATEGORIA" in datos_jugadores.columns:
            id_to_categoria = datos_jugadores.set_index("ID")["CATEGORIA"].to_dict()
            df_existente["CATEGORIA"] = df_existente["ID"].map(id_to_categoria)

    # Asegurar tipos string consistentes
    for col in ["JUGADOR", "CATEGORIA"]:
        if col in datos_jugadores.columns:
            datos_jugadores[col] = datos_jugadores[col].astype(str)
        if col in df_existente.columns:
            df_existente[col] = df_existente[col].astype(str)

    # === MODO 1: Se pasa una Ãºnica fecha ===
    if fecha:
        #existentes = df_existente[["ID"]].drop_duplicates()
        nuevos = datos_jugadores[~datos_jugadores["ID"].isin(df_existente["ID"])].copy()

        df_nuevo = pd.DataFrame(columns=columnas_estructura)
        for col in columnas_datos:
            if col in df_nuevo.columns and col in nuevos.columns:
                df_nuevo[col] = nuevos[col]

        df_nuevo["JUGADOR"] = nuevos["JUGADOR"]
        df_nuevo["CATEGORIA"] = nuevos["CATEGORIA"]
        df_nuevo["FECHA REGISTRO"] = fecha

    # === MODO 2: Detectar sesiones faltantes ===
    else:
        fechas_existentes = df_existente["FECHA REGISTRO"].dropna().unique().tolist()
        fechas_existentes = [f for f in fechas_existentes if isinstance(f, str)]

        jugadores_categoria = datos_jugadores[["JUGADOR", "CATEGORIA", "ID"]].drop_duplicates()

        combinaciones = pd.MultiIndex.from_product(
            [jugadores_categoria["JUGADOR"], jugadores_categoria["CATEGORIA"], fechas_existentes],
            names=["JUGADOR", "CATEGORIA", "FECHA REGISTRO"]
        ).to_frame(index=False)

        existentes = df_existente[["JUGADOR", "CATEGORIA", "FECHA REGISTRO"]].drop_duplicates()
        faltantes = combinaciones.merge(existentes, on=["JUGADOR", "CATEGORIA", "FECHA REGISTRO"], how="left", indicator=True)
        faltantes = faltantes[faltantes["_merge"] == "left_only"].drop(columns="_merge")

        df_nuevo = faltantes.merge(jugadores_categoria, on=["JUGADOR", "CATEGORIA"], how="left")
        df_nuevo = df_nuevo.merge(datos_jugadores, on=["ID", "JUGADOR", "CATEGORIA"], how="left")

    
    # === Finalizar df_nuevo ===
    if not df_nuevo.empty:
        if "FECHA REGISTRO" not in df_nuevo.columns:
            df_nuevo["FECHA REGISTRO"] = None

        df_nuevo = df_nuevo.drop_duplicates(subset=["JUGADOR", "CATEGORIA", "FECHA REGISTRO"])

        for col in columnas_estructura:
            if col not in df_nuevo.columns:
                df_nuevo[col] = None

        df_nuevo = df_nuevo[columnas_estructura]

        if "ID" in df_nuevo.columns:
            df_nuevo["ID"] = df_nuevo["ID"].astype(str)

        df_nuevo = df_nuevo[df_nuevo["FECHA REGISTRO"].notna()]
    else:
        df_nuevo = pd.DataFrame(columns=columnas_estructura)

    df_existente = df_existente.reset_index(drop=True)
    #st.dataframe(df_existente)
    # === Combinar ===
    df_final = pd.concat([df_existente, df_nuevo], ignore_index=True)
   

    # === Ordenar por fecha y jugador ===
    if "FECHA REGISTRO" in df_final.columns:
        df_final["FECHA REGISTRO"] = pd.to_datetime(df_final["FECHA REGISTRO"], format="%d/%m/%Y", errors="coerce")
        df_final = df_final.sort_values(by=["FECHA REGISTRO", "JUGADOR"]).reset_index(drop=True)
        df_final["FECHA REGISTRO"] = df_final["FECHA REGISTRO"].dt.strftime("%d/%m/%Y")

    # === Reordenar columnas: JUGADOR justo despuÃ©s de ID ===
    if "ID" in df_final.columns and "JUGADOR" in df_final.columns:
        cols = df_final.columns.tolist()
        cols.remove("JUGADOR")
        idx = cols.index("ID") + 1
        cols.insert(idx, "JUGADOR")
        df_final = df_final[cols]

    return df_final


def get_data_editor(df_nuevo, key=None, num_rows_user="fixed"):
    edited_df = st.data_editor(df_nuevo, key=key, column_config={
            "TEST": st.column_config.SelectboxColumn(
                label="TEST",
                options=["ENDURANCE I", "ENDURANCE II", "RECOVERY I", "RECOVERY II"],
                required=True,
                width="medium"
            )
        },num_rows=num_rows_user,
        hide_index=True) # ğŸ‘ˆ An editable dataframe
    return edited_df

def separar_dataframe_por_estructura(df_general, df_estructura, columnas_usadas):
    """
    Separa automÃ¡ticamente un DataFrame grande en mÃºltiples DataFrames,
    aÃ±adiendo siempre columnas clave al inicio y eliminando registros
    donde todas las mÃ©tricas especÃ­ficas sean NaN, None o 0.

    Args:
        df_general (DataFrame): El DataFrame con todas las mÃ©tricas.
        df_estructura (DataFrame): El DataFrame que define cÃ³mo separar.
        columnas_usadas (list): Columnas clave que siempre deben incluirse.

    Returns:
        dict: {nombre_hoja: DataFrame filtrado con columnas especÃ­ficas}
    """
    hojas_separadas = {}

    for hoja in df_estructura.columns:
        # 1. Obtener mÃ©tricas asociadas a esta hoja
        columnas_metrica = df_estructura[hoja].dropna().tolist()

        # 2. Validar columnas existentes en df_general
        columnas_existentes = [col for col in columnas_metrica if col in df_general.columns]

        # 3. Combinar con columnas clave
        columnas_finales = columnas_usadas + columnas_existentes

        # 4. Respetar el orden original de df_general
        columnas_finales = [col for col in df_general.columns if col in columnas_finales]

        if columnas_existentes:
            df_hoja = df_general[columnas_finales].copy()

            # 5. Filtrar registros donde todas las mÃ©tricas son NaN/None o 0
            metricas_validas = df_hoja[columnas_existentes].applymap(lambda x: pd.isna(x) or x == 0)
            filas_a_mantener = ~metricas_validas.all(axis=1)

            df_hoja_filtrado = df_hoja[filas_a_mantener].copy()

            hojas_separadas[hoja] = df_hoja_filtrado
        else:
            hojas_separadas[hoja] = pd.DataFrame()

    return hojas_separadas



######################

def actualizar_datos_con_checkin(df_datos, df_checkin, df_joined):
    """
    Actualiza el DataFrame df_datos con nuevos registros desde df_checkin,
    manteniendo la estructura original y eliminando duplicados. Luego realiza merge con df_joined.

    ParÃ¡metros:
        df_datos (pd.DataFrame): DataFrame original con datos existentes.
        df_checkin (pd.DataFrame): DataFrame de nuevos registros (check-in).
        df_joined (pd.DataFrame): DataFrame a combinar tras limpieza.

    Retorna:
        pd.DataFrame: DataFrame final actualizado y combinado.
    """

    # 1. Extraer columnas necesarias y eliminar duplicados
    df_nuevos = df_checkin[["JUGADOR", "CATEGORIA"]].drop_duplicates()

    # 2. Alinear estructura de columnas
    df_nuevos = df_nuevos.reindex(columns=df_datos.columns)

    # 3. Marcar el origen de cada DataFrame
    df_datos["PRIORIDAD"] = "1"
    df_nuevos["PRIORIDAD"] = "0"

    # 4. Concatenar
    df_datos_final = pd.concat([df_datos, df_nuevos], ignore_index=True)

    # 5. Eliminar duplicados por JUGADOR y CATEGORIA, manteniendo solo los que vienen de df_datos
    df_datos_final = df_datos_final.sort_values(by="PRIORIDAD", ascending=False)  # "datos" < "nuevos"
    df_datos_final = df_datos_final.drop_duplicates(subset=["JUGADOR", "CATEGORIA"], keep="first")

    # 6. Eliminar la columna auxiliar
    df_datos_final = df_datos_final.drop(columns="PRIORIDAD").reset_index(drop=True)

    # 7. Eliminar filas completamente vacÃ­as
    df_datos_final = df_datos_final.dropna(how="all").reset_index(drop=True)

    # 8. Realizar merge con df_joined
    df_data_test_final = merge_by_nombre_categoria(df_joined, df_checkin)

    if not df_data_test_final.empty:
        # Mapear nombres desde df_datos
        id_a_genero = df_datos_final.set_index("JUGADOR")["GENERO"].to_dict()
        df_data_test_final["GENERO"] = df_data_test_final["JUGADOR"].map(id_a_genero)

    #st.dataframe(df_datos_final)
    return df_data_test_final, df_datos_final

def merge_by_nombre_categoria(df_unido, df_nuevo):
    """
    Une dos DataFrames con estructura similar usando 'JUGADOR' y 'CATEGORIA' como claves.
    - Conserva el orden y columnas de df_unido.
    - Llena columnas faltantes en df_nuevo con NaN o 0 segÃºn tipo.
    - Limpia solo columnas numÃ©ricas.
    - Mantiene los valores originales de JUGADOR y CATEGORIA.
    """
    if df_unido.empty or df_nuevo.empty:
        return pd.DataFrame()

    # === Columnas que NO deben tocarse durante limpieza ===
    columnas_excluidas = ["FECHA REGISTRO", "ID", "EQUIPO", "TEST", "JUGADOR", "CATEGORIA", "GENERO"]
    columnas_estructura = get_dataframe_columns(df_nuevo)
    columnas_filtradas = [col for col in columnas_estructura if col not in columnas_excluidas]

    # === Procesamiento de fechas ===
    df_nuevo["FECHA REGISTRO"] = pd.to_datetime(df_nuevo["FECHA REGISTRO"], errors='coerce', dayfirst=True)
    df_nuevo["anio"] = df_nuevo["FECHA REGISTRO"].dt.year.astype(str)
    df_nuevo["mes"] = df_nuevo["FECHA REGISTRO"].dt.month.astype(str)
    df_nuevo = df_nuevo.sort_values(by="FECHA REGISTRO", ascending=False)
    df_nuevo["FECHA REGISTRO"] = df_nuevo["FECHA REGISTRO"].dt.strftime('%d/%m/%Y')

    # === Limpieza SOLO de columnas numÃ©ricas ===
    df_nuevo = limpiar_columnas_numericas(df_nuevo, columnas_filtradas)
    df_nuevo[columnas_filtradas] = df_nuevo[columnas_filtradas].fillna(0).replace("None", 0)

    # === Asegurar tipo texto correcto en claves ===
    df_nuevo["JUGADOR"] = df_nuevo["JUGADOR"].astype(str).str.strip()
    df_nuevo["CATEGORIA"] = df_nuevo["CATEGORIA"].astype(str).str.strip()

    # === Asegurar que df_nuevo tenga todas las columnas de df_unido ===
    columnas_faltantes = [col for col in df_unido.columns if col not in df_nuevo.columns]
    for col in columnas_faltantes:
        if df_unido[col].dtype.kind in "iufc":  # numÃ©rico
            df_nuevo[col] = 0
        else:
            df_nuevo[col] = None

    # === Reordenar columnas en el orden de df_unido ===
    df_nuevo = df_nuevo[df_unido.columns]

    # === Concatenar ===
    df_final = pd.concat([df_unido, df_nuevo], ignore_index=True)

    # === Eliminar duplicados si corresponde ===
    df_final = df_final.drop_duplicates(subset=["JUGADOR", "GENERO" ,"CATEGORIA", "FECHA REGISTRO"], keep="last")

    return df_final

def filtrar_por_rango_fechas(df, columna_fecha, fecha_inicio, fecha_fin, formato="%d/%m/%Y"):
    """
    Filtra un DataFrame por un rango de fechas, manteniendo la columna de fechas como string.
    Si la fecha de inicio y fin son iguales, no se aplica filtro.

    ParÃ¡metros:
        df (pd.DataFrame): DataFrame original.
        columna_fecha (str): Nombre de la columna que contiene fechas como string.
        fecha_inicio (datetime.date): Fecha inicial del rango.
        fecha_fin (datetime.date): Fecha final del rango.
        formato (str): Formato de fecha en el DataFrame (por defecto: "%d/%m/%Y").

    Retorna:
        pd.DataFrame: DataFrame filtrado, con la columna de fecha como string y sin columnas auxiliares.
    """
    df_temp = df.copy()
    df_temp["FECHA DT"] = pd.to_datetime(df_temp[columna_fecha], format=formato, errors="coerce")

    if fecha_inicio == fecha_fin:
        filtrado = df_temp  # No se filtra si ambas fechas son iguales
    else:
        filtrado = df_temp[
            (df_temp["FECHA DT"].dt.date >= fecha_inicio) &
            (df_temp["FECHA DT"].dt.date <= fecha_fin)
        ]

    return filtrado.drop(columns=["FECHA DT"])

# Utilidad para obtener lista Ãºnica ordenada de una columna, con filtros
def get_filtered_list(dataframe, column, filters, default_option="Todos"):
    for col, val in filters.items():
        if val != default_option:
            dataframe = dataframe[dataframe[col] == val]
    valores_unicos = dataframe[column].dropna().astype(str).str.strip().unique().tolist()
    return sorted(limpiar_lista(valores_unicos))

def limpiar_lista(valores):
    """
    Elimina elementos vacÃ­os, nulos o no informativos (NaN, None, '', 'nan', 'none') de una lista.
    """
    return [
        v for v in valores
        if pd.notna(v) and str(v).strip().lower() not in ["", "nan", "none"]
    ]

def get_filters(df):
    default_option = "Todos"

    # Diccionario con los filtros y sus valores seleccionados
    filters = {
        "CATEGORIA": default_option,
        "EQUIPO": default_option,
        "DEMARCACION": default_option,
        "NACIONALIDAD": default_option,
        "JUGADOR": default_option
    }

    # Layout en 5 columnas
    category_col, team_col, position_col, nationality_col, player_col = st.columns(5)

    with category_col:
        category_list = get_filtered_list(df, "CATEGORIA", {})
        filters["CATEGORIA"] = st.selectbox("CATEGORÃA:", options=[default_option] + category_list, index=0, key="categoria")
    with team_col:
        team_list = get_filtered_list(df, "EQUIPO", {"CATEGORIA": filters["CATEGORIA"]})
        filters["EQUIPO"] = st.selectbox("EQUIPO:", options=[default_option] + team_list)

    with position_col:
        position_list = get_filtered_list(df, "DEMARCACION", {
            "CATEGORIA": filters["CATEGORIA"],
            "EQUIPO": filters["EQUIPO"]
        })
        filters["DEMARCACION"] = st.selectbox("DEMARCACION:", options=[default_option] + position_list)

    with nationality_col:
        nationality_list = get_filtered_list(df, "NACIONALIDAD", {
            "CATEGORIA": filters["CATEGORIA"],
            "EQUIPO": filters["EQUIPO"],
            "DEMARCACION": filters["DEMARCACION"]
        })
        filters["NACIONALIDAD"] = st.selectbox("NACIONALIDAD:", options=[default_option] + nationality_list)

    with player_col:
        player_list = get_filtered_list(df, "JUGADOR", {
            "CATEGORIA": filters["CATEGORIA"],
            "EQUIPO": filters["EQUIPO"],
            "DEMARCACION": filters["DEMARCACION"],
            "NACIONALIDAD": filters["NACIONALIDAD"]
        })
        filters["JUGADOR"] = st.selectbox("JUGADOR:", options=[default_option] + player_list)

   
    # Verificar si se aplicÃ³ al menos un filtro (distinto de "Todos")
    if any(value != default_option for value in filters.values()):
         df_filtrado = df.copy()
         for col, val in filters.items():
             if val != default_option:
                 df_filtrado = df_filtrado[df_filtrado[col] == val]
         return df_filtrado
    
    # Si no se seleccionÃ³ ningÃºn filtro, retornar el original
    df = df.reset_index(drop=True)
    return df

def get_photo(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Verifica si hubo un error (por ejemplo, 404 o 500)
    except requests.exceptions.RequestException:
        response = None  # Si hay un error, no asignamos nada a response

    return response

def categorizar_grasa(porcentaje_grasa):
    if porcentaje_grasa is None:
        return "No disponible"
    elif porcentaje_grasa < 20:
        return "Saludable"
    else:
        return "No saludable"
    
def categorizar_imc(valor):
    if valor < 18.5:
        return "Bajo peso"
    elif 18.5 <= valor < 24.9:
        return "Normal"
    elif 25 <= valor < 29.9:
        return "Sobrepeso"
    else:
        return "Obesidad"

def color_categorias(val):
    color_mapping = {
        "Bajo peso": 0.2,  # MÃ¡s cercano a rojo
        "Normal": 0.8,  # MÃ¡s cercano a verde
        "Sobrepeso": 0.5,  # Amarillo
        "Obesidad": 0.1,  # Rojo fuerte
        "Saludable": 0.8,  # Verde
        "No saludable": 0.3  # Naranja/rojo
    }
    
    # Si el valor no estÃ¡ en el diccionario, devolver sin formato
    if val not in color_mapping:
        return ""
    
    # Normalizar el color en el rango de 0 (rojo) a 1 (verde)
    normalized = color_mapping[val]
    
    # Interpolar colores
    r = int(255 * (1 - normalized))  # Rojo disminuye con mayor valor
    g = int(255 * normalized)  # Verde aumenta con mayor valor
    b = 0  # Azul en 0 para tonos cÃ¡lidos
    opacity = 0.4  # Opacidad fija
    
    return f'background-color: rgba({r}, {g}, {b}, {opacity})'

def aplicar_semaforo(df, exclude_columns=["FECHA REGISTRO"], invertir=False):
    """
    Aplica un formato de color semÃ¡foro a un DataFrame.

    - Verde: mejor valor (segÃºn invertir).
    - Rojo: peor valor.
    - Amarillo: intermedio.
    - Blanco para columnas excluidas o valores NaN.

    ParÃ¡metros:
    df : pd.DataFrame
    exclude_columns : list -> columnas a excluir del formato.
    invertir : bool -> si True, valores bajos son mejores.

    Retorna:
    df.style
    """

    def semaforo(val, column):
        if column in exclude_columns or not np.issubdtype(df[column].dtype, np.number):
            return ''

        if pd.isna(val):
            return 'background-color: rgba(255, 255, 255, 0)'

        col_min = df[column].min()
        col_max = df[column].max()

        # NormalizaciÃ³n
        if col_max != col_min:
            normalized = (val - col_min) / (col_max - col_min)
        else:
            normalized = 0.5  # todos iguales

        if invertir:
            normalized = 1 - normalized

        # Interpolar colores
        r = int(255 * (1 - normalized))
        g = int(255 * normalized)
        b = 0
        opacity = 0.4

        return f'background-color: rgba({r}, {g}, {b}, {opacity})'

    styled_df = df.style.apply(lambda x: [semaforo(val, x.name) for val in x], axis=0)

    numeric_columns = [col for col in df.select_dtypes(include=[np.number]).columns if col not in exclude_columns]
    styled_df = styled_df.format({col: "{:.2f}" for col in numeric_columns})

    return styled_df

def contar_jugadores_por_categoria(df):
    """
    Retorna un DataFrame con las categorÃ­as como columnas y la cantidad de jugadores Ãºnicos en cada una.

    ParÃ¡metros:
    df : pd.DataFrame -> DataFrame con la informaciÃ³n de los jugadores, debe contener la columna 'CATEGORIA' y 'JUGADOR'.

    Retorna:
    pd.DataFrame -> DataFrame con las categorÃ­as como columnas y la cantidad de jugadores por categorÃ­a.
    """
    # Contar jugadores Ãºnicos por categorÃ­a
    jugadores_por_categoria = df.groupby("CATEGORIA")["JUGADOR"].nunique()

    # Convertir a DataFrame con categorÃ­as como columnas
    resultado = jugadores_por_categoria.to_frame().T

    return resultado
    
def resumen_sesiones(df, total_jugadores):
    """
    Calcula la cantidad de sesiones en los dos Ãºltimos meses, la asistencia promedio en cada mes,
    la cantidad de jugadores en la Ãºltima sesiÃ³n de cada mes y la fecha de la Ãºltima sesiÃ³n.

    ParÃ¡metros:
    df : pd.DataFrame -> DataFrame con los registros de sesiones.
    total_jugadores : int -> NÃºmero total de jugadores posibles a asistir.

    Retorna:
    pd.DataFrame -> Resumen de sesiones en el Ãºltimo mes y penÃºltimo mes.
    """

    # Verificar si el DataFrame estÃ¡ vacÃ­o o no tiene las columnas necesarias
    if df.empty or "FECHA REGISTRO" not in df or "ID" not in df:
        return pd.DataFrame({"MES": ["Ãšltimo", "PenÃºltimo"], "TSUM": [0, 0], "APUS": [0, 0], "JUS": [0, 0], "FUS": [None, None]})

    # Convertir FECHA REGISTRO a datetime
    df["FECHA REGISTRO"] = pd.to_datetime(df["FECHA REGISTRO"], dayfirst=True, errors='coerce')

    # Verificar si hay fechas vÃ¡lidas
    if df["FECHA REGISTRO"].isna().all():
        return pd.DataFrame({"MES": ["Ãšltimo", "PenÃºltimo"], "TSUM": [0, 0], "APUS": [0, 0], "JUS": [0, 0], "FUS": [None, None]})

    # Ãšltima fecha de sesiÃ³n vÃ¡lida
    ultima_fecha = df["FECHA REGISTRO"].max()

    # Definir los rangos de tiempo
    un_mes_atras = ultima_fecha - pd.DateOffset(months=1)
    dos_meses_atras = ultima_fecha - pd.DateOffset(months=2)

    df_ultimo_mes = df[df["FECHA REGISTRO"] >= un_mes_atras]
    df_penultimo_mes = df[(df["FECHA REGISTRO"] >= dos_meses_atras) & (df["FECHA REGISTRO"] < un_mes_atras)]

    def calcular_resumen(df_periodo, nombre_mes):
        if df_periodo.empty:
            return {"MES": nombre_mes, "TSUM": 0, "APUS": 0, "JUS": 0, "FUS": None}
        
        # Contar sesiones Ãºnicas
        sesiones_mes = df_periodo.groupby("FECHA REGISTRO")["ID"].nunique().sum()
        
        # Ãšltima sesiÃ³n del periodo
        ultima_fecha_periodo = df_periodo["FECHA REGISTRO"].max()
        jugadores_ultima_sesion = df[df["FECHA REGISTRO"] == ultima_fecha_periodo]["ID"].nunique()

        # Calcular asistencia promedio
        asistencia_promedio = jugadores_ultima_sesion / total_jugadores if total_jugadores > 0 else 0

        return {
            "MES": nombre_mes,
            "TSUM": sesiones_mes,
            "APUS": asistencia_promedio,
            "JUS": jugadores_ultima_sesion,
            "FUS": ultima_fecha_periodo.strftime('%d/%m/%Y') if pd.notna(ultima_fecha_periodo) else None
        }

    # Calcular resumen para ambos meses
    resumen_ultimo_mes = calcular_resumen(df_ultimo_mes, "Ãšltimo")
    resumen_penultimo_mes = calcular_resumen(df_penultimo_mes, "PenÃºltimo")

    # Crear DataFrame con los resultados
    resumen_df = pd.DataFrame([resumen_ultimo_mes, resumen_penultimo_mes])

    return resumen_df

def sesiones_por_test(df_joined, test_categorias):
    """
    Cuenta la cantidad de sesiones por jugador y categorÃ­a, y por tipo de test.
    TambiÃ©n agrega la fecha de la Ãºltima sesiÃ³n registrada por cada jugador.

    ParÃ¡metros:
        df_joined (pd.DataFrame): DataFrame con los registros de sesiones.
        test_categorias (dict): Diccionario con los tipos de test y sus columnas asociadas.

    Retorna:
        pd.DataFrame: Cantidad de sesiones por jugador/categorÃ­a, tipo de test y su Ãºltima sesiÃ³n.
    """
    
    if df_joined.empty:
        return pd.DataFrame()
    
    df = pd.DataFrame(df_joined)

    # Verificar columnas esenciales
    columnas_requeridas = {"JUGADOR", "CATEGORIA", "FECHA REGISTRO"}
    if not columnas_requeridas.issubset(df.columns):
        return pd.DataFrame()

    # Convertir fecha
    df["FECHA REGISTRO"] = pd.to_datetime(df["FECHA REGISTRO"], errors='coerce', dayfirst=True)
    df = df.dropna(subset=["FECHA REGISTRO"])

    # Inicializar diccionario de resultados
    sesiones_dict = {"JUGADOR": [], "CATEGORIA": [], "ÃšLTIMA SESIÃ“N": []}
    for test in test_categorias:
        sesiones_dict[test] = []

    # Agrupar por nombre y categorÃ­a
    for (jugador_nombre, categoria), datos_jugador in df.groupby(["JUGADOR", "CATEGORIA"]):
        sesiones_dict["JUGADOR"].append(jugador_nombre)
        sesiones_dict["CATEGORIA"].append(categoria)
        sesiones_dict["ÃšLTIMA SESIÃ“N"].append(datos_jugador["FECHA REGISTRO"].max().strftime("%d/%m/%Y"))

        for test, columnas in test_categorias.items():
            columnas_validas = [col for col in columnas if col in datos_jugador.columns]
            if columnas_validas:
                sesiones_validas = datos_jugador[columnas_validas].apply(lambda x: (x != 0).any(), axis=1)
                sesiones_dict[test].append(sesiones_validas.sum())
            else:
                sesiones_dict[test].append(0)

    # Crear DataFrame final y ordenar
    sesiones_df = pd.DataFrame(sesiones_dict)
    sesiones_df["ÃšLTIMA SESIÃ“N"] = pd.to_datetime(sesiones_df["ÃšLTIMA SESIÃ“N"], format="%d/%m/%Y")
    sesiones_df = sesiones_df.sort_values(by="ÃšLTIMA SESIÃ“N", ascending=False).reset_index(drop=True)
    sesiones_df["ÃšLTIMA SESIÃ“N"] = sesiones_df["ÃšLTIMA SESIÃ“N"].dt.strftime('%d/%m/%Y').astype(str)

    return sesiones_df

def obtener_columnas_unidas(test_cat, clave, columnas_fecha_registro):
    """
    Combina la columna 'FECHA REGISTRO' con las columnas de la lista asociada
    a 'clave' dentro del diccionario 'test_cat', evitando duplicados.

    ParÃ¡metros:
    - test_cat (dict): Diccionario que contiene listas de columnas por clave.
    - clave (str): Clave de la lista a extraer y unir con 'FECHA REGISTRO'.

    Retorna:
    - list: Lista de columnas con 'FECHA REGISTRO' al principio y sin duplicados.
    """
    lista_test_cat = list(test_cat.get(clave, []))
    columnas_unidas = columnas_fecha_registro + [col for col in lista_test_cat if col != "FECHA REGISTRO"]
    return columnas_unidas


def construir_diccionario_test_categorias(df_columnas_raw):
    """
    Convierte un DataFrame con columnas por categorÃ­a de test y valores por fila
    en un diccionario con estructura tipo: {"TEST": [mÃ©tricas]}
    """
    test_categorias = {}

    for col in df_columnas_raw.columns:
        valores = df_columnas_raw[col].dropna().astype(str).str.strip().tolist()
        test_categorias[col.strip()] = valores

    return test_categorias


def get_diccionario_test_categorias(conn):
    test = get_test(conn)
    test_cat = construir_diccionario_test_categorias(test)
    lista_columnas = test.columns.tolist()

    return test, test_cat, lista_columnas

# FunciÃ³n para eliminar acentos
def quitar_acentos(texto):
    if not isinstance(texto, str):
        return texto
    # DescomposiciÃ³n Unicode
    texto_normalizado = unicodedata.normalize('NFD', texto)
    # Elimina tildes pero deja la Ã±
    texto_sin_tildes = ''.join(
        c for c in texto_normalizado
        if unicodedata.category(c) != 'Mn' or c == 'Ìƒ' and texto_normalizado[texto_normalizado.index(c)-1].lower() == 'n'
    )
    return texto_sin_tildes

def obtener_bandera(pais):
    # Diccionario de cÃ³digos de paÃ­s ISO 3166-1 alfa-2
    paises = {
        "AFGANISTAN": "ğŸ‡¦ğŸ‡«", "ALBANIA": "ğŸ‡¦ğŸ‡±", "ALEMANIA": "ğŸ‡©ğŸ‡ª", "ANDORRA": "ğŸ‡¦ğŸ‡©",
        "ANGOLA": "ğŸ‡¦ğŸ‡´","ANTIGUA Y BARBUDA": "ğŸ‡¦ğŸ‡¬", "ARABIA SAUDITA": "ğŸ‡¸ğŸ‡¦","ARGELIA": "ğŸ‡©ğŸ‡¿",
        "ARGENTINA": "ğŸ‡¦ğŸ‡·","ARMENIA": "ğŸ‡¦ğŸ‡²", "AUSTRALIA": "ğŸ‡¦ğŸ‡º","AUSTRIA": "ğŸ‡¦ğŸ‡¹","AZERBAIYAN": "ğŸ‡¦ğŸ‡¿",
        "BAHAMAS": "ğŸ‡§ğŸ‡¸","BANGLADES": "ğŸ‡§ğŸ‡©","BARBADOS": "ğŸ‡§ğŸ‡§","BAREIN": "ğŸ‡§ğŸ‡­","BELGICA": "ğŸ‡§ğŸ‡ª","BELICE": "ğŸ‡§ğŸ‡¿","BENIN": "ğŸ‡§ğŸ‡¯",
        "BIELORRUSIA": "ğŸ‡§ğŸ‡¾","BIRMANIA": "ğŸ‡²ğŸ‡²","BOLIVIA": "ğŸ‡§ğŸ‡´","BOSNIA Y HERZEGOVINA": "ğŸ‡§ğŸ‡¦","BOTSUANA": "ğŸ‡§ğŸ‡¼","BRASIL": "ğŸ‡§ğŸ‡·",
        "BRUNEI": "ğŸ‡§ğŸ‡³","BULGARIA": "ğŸ‡§ğŸ‡¬","BURKINA FASO": "ğŸ‡§ğŸ‡«","BURUNDI": "ğŸ‡§ğŸ‡®","BUTAN": "ğŸ‡§ğŸ‡¹","CABO VERDE": "ğŸ‡¨ğŸ‡»",
        "CAMBOYA": "ğŸ‡°ğŸ‡­","CAMERUN": "ğŸ‡¨ğŸ‡²","CANADA": "ğŸ‡¨ğŸ‡¦","CATAR": "ğŸ‡¶ğŸ‡¦","CHAD": "ğŸ‡¹ğŸ‡©","CHILE": "ğŸ‡¨ğŸ‡±","CHINA": "ğŸ‡¨ğŸ‡³","CHIPRE": "ğŸ‡¨ğŸ‡¾",
        "COLOMBIA": "ğŸ‡¨ğŸ‡´","COMORAS": "ğŸ‡°ğŸ‡²","COREA DEL NORTE": "ğŸ‡°ğŸ‡µ","COREA DEL SUR": "ğŸ‡°ğŸ‡·","COSTA DE MARFIL": "ğŸ‡¨ğŸ‡®",
        "COSTA RICA": "ğŸ‡¨ğŸ‡·","CROACIA": "ğŸ‡­ğŸ‡·","CUBA": "ğŸ‡¨ğŸ‡º","DINAMARCA": "ğŸ‡©ğŸ‡°","DOMINICA": "ğŸ‡©ğŸ‡²","ECUADOR": "ğŸ‡ªğŸ‡¨","EGIPTO": "ğŸ‡ªğŸ‡¬",
        "EL SALVADOR": "ğŸ‡¸ğŸ‡»","EMIRATOS ARABES UNIDOS": "ğŸ‡¦ğŸ‡ª","ERITREA": "ğŸ‡ªğŸ‡·","ESLOVAQUIA": "ğŸ‡¸ğŸ‡°","ESLOVENIA": "ğŸ‡¸ğŸ‡®",
        "ESPANA": "ğŸ‡ªğŸ‡¸","ESTADOS UNIDOS": "ğŸ‡ºğŸ‡¸","ESTONIA": "ğŸ‡ªğŸ‡ª","ETIOPIA": "ğŸ‡ªğŸ‡¹","FIJI": "ğŸ‡«ğŸ‡¯","FILIPINAS": "ğŸ‡µğŸ‡­",
        "FINLANDIA": "ğŸ‡«ğŸ‡®","FRANCIA": "ğŸ‡«ğŸ‡·","GABON": "ğŸ‡¬ğŸ‡¦","GAMBIA": "ğŸ‡¬ğŸ‡²","GEORGIA": "ğŸ‡¬ğŸ‡ª","GHANA": "ğŸ‡¬ğŸ‡­","GRANADA": "ğŸ‡¬ğŸ‡©",
        "GRECIA": "ğŸ‡¬ğŸ‡·","GUATEMALA": "ğŸ‡¬ğŸ‡¹","GUINEA": "ğŸ‡¬ğŸ‡³","GUINEA BISSAU": "ğŸ‡¬ğŸ‡¼","GUINEA ECUATORIAL": "ğŸ‡¬ğŸ‡¶","GUYANA": "ğŸ‡¬ğŸ‡¾",
        "HAITI": "ğŸ‡­ğŸ‡¹","HOLANDA": "ğŸ‡³ğŸ‡±","HONDURAS": "ğŸ‡­ğŸ‡³","HUNGRIA": "ğŸ‡­ğŸ‡º","INDIA": "ğŸ‡®ğŸ‡³","INDONESIA": "ğŸ‡®ğŸ‡©","INGLATERRA": "ğŸ‡¬ğŸ‡§",
        "IRAK": "ğŸ‡®ğŸ‡¶","IRAN": "ğŸ‡®ğŸ‡·","IRLANDA": "ğŸ‡®ğŸ‡ª","ISLANDIA": "ğŸ‡®ğŸ‡¸","ISLAS MARSHALL": "ğŸ‡²ğŸ‡­","ISLAS SALOMON": "ğŸ‡¸ğŸ‡§",
        "ISLAS VIRGENES": "ğŸ‡»ğŸ‡¬","ISRAEL": "ğŸ‡®ğŸ‡±","ITALIA": "ğŸ‡®ğŸ‡¹","JAMAICA": "ğŸ‡¯ğŸ‡²","JAPON": "ğŸ‡¯ğŸ‡µ","JORDANIA": "ğŸ‡¯ğŸ‡´","KAZAJISTAN": "ğŸ‡°ğŸ‡¿",
        "KENIA": "ğŸ‡°ğŸ‡ª","KIRGUISTAN": "ğŸ‡°ğŸ‡¬","KIRIBATI": "ğŸ‡°ğŸ‡®","KUWAIT": "ğŸ‡°ğŸ‡¼","LAOS": "ğŸ‡±ğŸ‡¦","LESOTO": "ğŸ‡±ğŸ‡¸","LETONIA": "ğŸ‡±ğŸ‡»",
        "LIBANO": "ğŸ‡±ğŸ‡§","LIBERIA": "ğŸ‡±ğŸ‡·","LIBIA": "ğŸ‡±ğŸ‡¾","LIECHTENSTEIN": "ğŸ‡±ğŸ‡®","LITUANIA": "ğŸ‡±ğŸ‡¹","LUXEMBURGO": "ğŸ‡±ğŸ‡º",
        "MACEDONIA DEL NORTE": "ğŸ‡²ğŸ‡°","MADAGASCAR": "ğŸ‡²ğŸ‡¬","MALASIA": "ğŸ‡²ğŸ‡¾","MALAUI": "ğŸ‡²ğŸ‡¼","MALDIVAS": "ğŸ‡²ğŸ‡»","MALI": "ğŸ‡²ğŸ‡±",
        "MALTA": "ğŸ‡²ğŸ‡¹","MARRUECOS": "ğŸ‡²ğŸ‡¦","MAURICIO": "ğŸ‡²ğŸ‡º","MAURITANIA": "ğŸ‡²ğŸ‡·","MEXICO": "ğŸ‡²ğŸ‡½","MICRONESIA": "ğŸ‡«ğŸ‡²",
        "MOLDAVIA": "ğŸ‡²ğŸ‡©","MONACO": "ğŸ‡²ğŸ‡¨","MONGOLIA": "ğŸ‡²ğŸ‡³","MONTENEGRO": "ğŸ‡²ğŸ‡ª","MOZAMBIQUE": "ğŸ‡²ğŸ‡¿","NAMIBIA": "ğŸ‡³ğŸ‡¦","NAURU": "ğŸ‡³ğŸ‡·",
        "NEPAL": "ğŸ‡³ğŸ‡µ","NICARAGUA": "ğŸ‡³ğŸ‡®","NIGER": "ğŸ‡³ğŸ‡ª","NIGERIA": "ğŸ‡³ğŸ‡¬","NORUEGA": "ğŸ‡³ğŸ‡´","NUEVA ZELANDA": "ğŸ‡³ğŸ‡¿","OMÃN": "ğŸ‡´ğŸ‡²",
        "PAISES BAJOS": "ğŸ‡³ğŸ‡±","PAKISTAN": "ğŸ‡µğŸ‡°","PALAOS": "ğŸ‡µğŸ‡¼","PALESTINA": "ğŸ‡µğŸ‡¸","PANAMA": "ğŸ‡µğŸ‡¦","PAPUA NUEVA GUINEA": "ğŸ‡µğŸ‡¬",
        "PARAGUAY": "ğŸ‡µğŸ‡¾","PERU": "ğŸ‡µğŸ‡ª","POLINESIA FRANCESA": "ğŸ‡µğŸ‡«","POLONIA": "ğŸ‡µğŸ‡±","PORTUGAL": "ğŸ‡µğŸ‡¹","R. DOMINICANA": "ğŸ‡©ğŸ‡´",
        "R.D. DEL CONGO": "ğŸ‡¨ğŸ‡©","R. DEL CONGO": "ğŸ‡¨ğŸ‡¬","REINO UNIDO": "ğŸ‡¬ğŸ‡§","REPUBLICA CENTROAFRICANA": "ğŸ‡¨ğŸ‡«",
        "REPUBLICA CHECA": "ğŸ‡¨ğŸ‡¿","RUANDA": "ğŸ‡·ğŸ‡¼","RUMANIA": "ğŸ‡·ğŸ‡´","RUSIA": "ğŸ‡·ğŸ‡º","SAMOA": "ğŸ‡¼ğŸ‡¸","SAN CRISTOBAL Y NIEVES": "ğŸ‡°ğŸ‡³",
        "SAN MARINO": "ğŸ‡¸ğŸ‡²","SAN VICENTE Y LAS GRANADINAS": "ğŸ‡»ğŸ‡¨","SANTA LUCIA": "ğŸ‡±ğŸ‡¨","SANTO TOME Y PRINCIPE": "ğŸ‡¸ğŸ‡¹",
        "SENEGAL": "ğŸ‡¸ğŸ‡³","SERBIA": "ğŸ‡·ğŸ‡¸","SEYCHELLES": "ğŸ‡¸ğŸ‡¨","SIERRA LEONA": "ğŸ‡¸ğŸ‡±","SINGAPUR": "ğŸ‡¸ğŸ‡¬","SIRIA": "ğŸ‡¸ğŸ‡¾",
        "SOMALIA": "ğŸ‡¸ğŸ‡´","SRI LANKA": "ğŸ‡±ğŸ‡°","SUAZILANDIA": "ğŸ‡¸ğŸ‡¿","SUDAFRICA": "ğŸ‡¿ğŸ‡¦","SUDAN": "ğŸ‡¸ğŸ‡©","SUDAN DEL SUR": "ğŸ‡¸ğŸ‡¸",
        "SUECIA": "ğŸ‡¸ğŸ‡ª","SUIZA": "ğŸ‡¨ğŸ‡­","SURINAM": "ğŸ‡¸ğŸ‡·","TAILANDIA": "ğŸ‡¹ğŸ‡­","TANZANIA": "ğŸ‡¹ğŸ‡¿","TAYIKISTAN": "ğŸ‡¹ğŸ‡¯",
        "TIMOR ORIENTAL": "ğŸ‡¹ğŸ‡±","TOGO": "ğŸ‡¹ğŸ‡¬","TONGA": "ğŸ‡¹ğŸ‡´","TRINIDAD Y TOBAGO": "ğŸ‡¹ğŸ‡¹","TUNEZ": "ğŸ‡¹ğŸ‡³","TURKMENISTAN": "ğŸ‡¹ğŸ‡²",
        "TURQUIA": "ğŸ‡¹ğŸ‡·","TUVALU": "ğŸ‡¹ğŸ‡»","UCRANIA": "ğŸ‡ºğŸ‡¦","UGANDA": "ğŸ‡ºğŸ‡¬","URUGUAY": "ğŸ‡ºğŸ‡¾","UZBEKISTAN": "ğŸ‡ºğŸ‡¿","VANUATU": "ğŸ‡»ğŸ‡º",
        "VATICANO": "ğŸ‡»ğŸ‡¦","VENEZUELA": "ğŸ‡»ğŸ‡ª","VIETNAM": "ğŸ‡»ğŸ‡³","YEMEN": "ğŸ‡¾ğŸ‡ª","YIBUTI": "ğŸ‡©ğŸ‡¯","ZAMBIA": "ğŸ‡¿ğŸ‡²","ZIMBABUE": "ğŸ‡¿ğŸ‡¼"
    }



    # Normalizar el nombre del paÃ­s
    pais = pais.strip().upper()

    if pais in paises:
        codigo = paises[pais]
        # Convertir el cÃ³digo de paÃ­s a su bandera en Unicode
        #bandera_unicode = ''.join(chr(0x1F1E6 + ord(c)) for c in codigo)
        return codigo
    else:
        return ""
    

def calcular_percentiles(jugador, referencia, columnas_estructura):
    percentiles = {}
    #st.dataframe(referencia)
    #columnas_estructura = get_dataframe_columns(jugador)
    for variable in columnas_estructura:
        ref = referencia[variable].dropna().astype(float)
        valor = jugador[variable]
        percentil = percentileofscore(ref, valor, kind='rank')
        percentiles[variable] = round(percentil, 1)
    return percentiles

def obtener_color_percentil(p):
    if p is None or pd.isna(p):
        return (255, 255, 255), "Sin datos suficientes" # âšª 
    if p < 25:
        return (255, 69, 58), "Por debajo del promedio"  # ğŸ”´
    elif p < 50:
        return (255, 165, 0), "Ligeramente inferior"     # ğŸŸ 
    elif p < 75:
        return (255, 225, 0), "En el promedio o superior" # ğŸŸ¡
    else:
        return (52, 235, 58), "Muy por encima del promedio"  # ğŸŸ¢

def interpretar_percentil(p):
    if p is None or pd.isna(p):
        return "âšª Sin datos suficientes"
    elif p < 25:
        return "ğŸ”´ Por debajo del promedio"
    elif p < 50:
        return "ğŸŸ  Ligeramente inferior a la media"
    elif p < 75:
        return "ğŸŸ¡ En el promedio o superior"
    else:
        return "ğŸŸ¢ Muy por encima del promedio"

def get_rgb_from_categoria(val):
    color_mapping = {
        "Bajo peso": 0.2,
        "Normal": 0.8,
        "Sobrepeso": 0.5,
        "Obesidad": 0.1,
        "Saludable": 0.8,
        "No saludable": 0.3
    }
    if val not in color_mapping:
        return (255, 255, 255)  # Blanco si no se reconoce
    normalized = color_mapping[val]
    r = int(255 * (1 - normalized))
    g = int(255 * normalized)
    b = 0
    return (r, g, b)

def get_demarcaciones():
    return {
        "PORTERO": "POR",
        "PORTERA": "POR",
        "DEFENSA CENTRAL": "DFC",
        "CENTRAL": "DFC",
        "LATERAL DERECHO": "LD",
        "LATERAL IZQUIERDO": "LI",
        "MEDIOCENTRO DEFENSIVO": "MC",
        "MEDIOCENTRO": "MC",
        "MEDIAPUNTA": "MC",         
        "EXTREMO": "EX", 
        "EXTREMO IZQUIERDO": "EI", 
        "EXTREMO DERECHO": "ED",
        "LATERAL": "LA",             
        "DELANTERO": "DC",
        "DELANTERA": "DC",
        "NO DISPONIBLE": "ND"
    }

def convertir_m_s_a_km_h(df, metricas_m_s):
    """
    AÃ±ade columnas nuevas transformadas de m/s a km/h para las columnas indicadas.

    Args:
        df (pd.DataFrame): DataFrame original.
        metricas_m_s (list): Lista de nombres de columnas en m/s a convertir.

    Returns:
        pd.DataFrame: DataFrame con columnas nuevas en km/h.
    """
    df = df.copy()

    for col in metricas_m_s:
        if col in df.columns:
            import re
            nueva_col = re.sub(r"\s*\(M[/*]?S(EG)?\)", " (KM/H)", col, flags=re.IGNORECASE)
            df[nueva_col] = df[col] * 3.6

    return df

def calcular_promedios_filtrados(df, columnas_a_verificar, categorial, equipol, equipo_promedio):
    """
    Calcula el promedio por GENERO, CATEGORIA y EQUIPO, ignorando valores 0 y NaN por columna.
    Asigna valores manuales para hombres. Si no existen registros femeninos, los aÃ±ade.

    Args:
        df (pd.DataFrame): DataFrame con los datos originales.
        columnas_a_verificar (list): Columnas a calcular.
        categorial (str): Nombre de la columna de categorÃ­a.
        equipol (str): Nombre de la columna de equipo.
        equipo_promedio (str): Equipo base para valores por defecto.

    Returns:
        pd.DataFrame: DataFrame con los promedios calculados y registros aÃ±adidos si es necesario.
    """
    filas_promedio = []

    for (genero, categoria, equipo), grupo in df.groupby(["GENERO", "CATEGORIA", "EQUIPO"]):
        fila = {
            "GENERO": genero,
            "CATEGORIA": categoria,
            "EQUIPO": equipo
        }
        for columna in columnas_a_verificar:
            datos_columna = pd.to_numeric(grupo[columna], errors="coerce")
            datos_validos = datos_columna[(datos_columna != 0) & (~datos_columna.isna())]
            fila[columna] = datos_validos.mean() if not datos_validos.empty else np.nan
        filas_promedio.append(fila)

    df_promedios = pd.DataFrame(filas_promedio).round(2)

    # --- Valores manuales para Hombres ---
    condiciones_h = {
        "Cadete": {"DISTANCIA ACUMULADA (M)": 1400, "ALTURA-(CM)": 35.00, "TIEMPO 0-40M (SEG)": 5.7},
        "Juvenil": {"DISTANCIA ACUMULADA (M)": 1900, "ALTURA-(CM)": 39.00, "TIEMPO 0-40M (SEG)": 5.2},
    }

    for categoria_val, valores in condiciones_h.items():
        df_promedios.loc[
            (df_promedios["GENERO"] == "H") &
            (df_promedios[categorial] == categoria_val) &
            (df_promedios[equipol] == equipo_promedio),
            list(valores.keys())
        ] = list(valores.values())

    # --- Valores manuales para Mujeres (si no existen) ---
    condiciones_m = {
        "Cadete": {"DISTANCIA ACUMULADA (M)": 1400, "ALTURA-(CM)": 23.00, "TIEMPO 0-40M (SEG)": 6.4},
        "Juvenil": {"DISTANCIA ACUMULADA (M)": 1900, "ALTURA-(CM)": 25.00, "TIEMPO 0-40M (SEG)": 6.2},
    }

    for categoria_val, valores in condiciones_m.items():
        existe_femenino = (
            ((df_promedios["GENERO"] == "M") &
             (df_promedios[categorial] == categoria_val) &
             (df_promedios[equipol] == equipo_promedio))
            .any()
        )

        if not existe_femenino:
            nueva_fila = {
                "GENERO": "M",
                "CATEGORIA": categoria_val,
                "EQUIPO": equipo_promedio,
                **{col: np.nan for col in columnas_a_verificar}  # Inicializar todas
            }
            nueva_fila.update(valores)
            df_promedios = pd.concat([df_promedios, pd.DataFrame([nueva_fila])], ignore_index=True)

    return df_promedios

def obtener_promedio_genero(df_promedios, categoria, equipo_promedio, columna, genero):
    """
    Devuelve el promedio filtrado por categorÃ­a, equipo y gÃ©nero.

    Args:
        df_promedios (DataFrame): DataFrame de promedios.
        categoria (str): CategorÃ­a ("Cadete", "Juvenil", etc.).
        equipo_promedio (str): Nombre del equipo promedio.
        columna (str): Columna mÃ©trica a consultar.
        genero (str): "H" o "M".

    Returns:
        float or None: Promedio si existe, de lo contrario None.
    """
    filtro = (
        (df_promedios["GENERO"] == genero) &
        (df_promedios["CATEGORIA"] == categoria) &
        (df_promedios["EQUIPO"] == equipo_promedio)
    )

    valores = df_promedios.loc[filtro, columna]

    if not valores.empty:
        return float(valores.values[0])
    else:
        return None

def obtener_promedios_metricas_genero(df_promedios, categoria, equipo, metricas, genero, tipo="CMJ"):
    """
    Filtra el DataFrame por CATEGORIA, EQUIPO y GENERO, y devuelve un diccionario con los valores promedio
    por cada mÃ©trica solicitada.

    Args:
        df_promedios (DataFrame): DataFrame con promedios.
        categoria (str): CategorÃ­a del jugador (e.g., 'Juvenil', 'Cadete').
        equipo (str): Nombre del equipo.
        metricas (list): Lista de columnas a evaluar.
        genero (str): 'H' o 'M'.
        tipo (str): Para identificar el contexto del aviso (CMJ, Sprint, etc.)

    Returns:
        dict: Diccionario con mÃ©tricas y sus valores promedio si existen.
    """
    # Forzar tipos seguros
    for col in ["GENERO", "CATEGORIA", "EQUIPO"]:
        if col in df_promedios.columns:
            df_promedios[col] = df_promedios[col].astype(str)

    filtro = (
        (df_promedios["GENERO"] == genero) &
        (df_promedios["CATEGORIA"] == categoria) &
        (df_promedios["EQUIPO"] == equipo)
    )

    promedio_row = df_promedios.loc[filtro]
    #st.text(metricas)
    promedios = {}
    if not promedio_row.empty:
        for metrica in metricas:
            if metrica in promedio_row.columns:
                valor = promedio_row[metrica].values[0]
                if pd.notna(valor):
                    promedios[metrica] = float(valor)
    else:
        st.warning(f"No se encontraron promedios de {tipo} para la categorÃ­a, equipo y gÃ©nero especificados.")

    return promedios

def get_observacion_grasa(grasa, categoria, gender):

    if "juvenil" in categoria:
        if grasa > 15:
            return (
                "Porcentajes > 15% de grasa corporal representa:\n"
                "- Aumento en la incidencia de lesiones mÃºsculoesquelÃ©ticas.\n"
                "- Acelera la apariciÃ³n de fatiga.\n"
                "- Disminuye la eficiencia energÃ©tica y el rendimiento fÃ­sico.\n"
                "- Afecta parÃ¡metros hormonales y metabÃ³licos.\n"
                "- Recomendamos realizar un seguimiento con un nutricionista.")
        elif grasa < 7:
            if gender == "H":
                return (
                    "Porcentajes menores al 7% de grasa corporal representan:\n"
                    "- Aumento en la incidencia de lesiones mÃºsculoesquelÃ©ticas.\n"
                    "- AceleraciÃ³n en la apariciÃ³n de la fatiga.\n"
                    "- DisminuciÃ³n de la eficiencia energÃ©tica y del rendimiento fÃ­sico.\n"
                    "- Alteraciones en parÃ¡metros hormonales y metabÃ³licos.\n"
                    "- Se recomienda realizar un seguimiento con un nutricionista deportivo."
                )
            else:
                return (
                    "Porcentajes menores al 8% de grasa corporal representan:\n"
                    "- Aumento en la incidencia de lesiones mÃºsculoesquelÃ©ticas.\n"
                    "- AceleraciÃ³n en la apariciÃ³n de la fatiga.\n"
                    "- DisminuciÃ³n de la eficiencia energÃ©tica y del rendimiento fÃ­sico.\n"
                    "- Alteraciones en parÃ¡metros hormonales y metabÃ³licos.\n"
                    "- Se recomienda realizar un seguimiento con un nutricionista deportivo."
                )
        else:
            return "Tu nivel de grasa corporal estÃ¡ en el rango ideal para un futbolista de alto rendimiento."
    
    elif "cadete" in categoria:
        if grasa > 17:
            return (
                "Porcentajes > 17% de grasa corporal representa:\n"
                "- Aumento en la incidencia de lesiones mÃºsculoesquelÃ©ticas.\n"
                "- Acelera la apariciÃ³n de fatiga.\n"
                "- Disminuye la eficiencia energÃ©tica y el rendimiento fÃ­sico.\n"
                "- Afecta parÃ¡metros hormonales y metabÃ³licos.\n"
                "- Recomendamos realizar un seguimiento con un nutricionista deportivo.")
        elif grasa < 8:
            return (
                "Porcentajes menores al 8% de grasa corporal representan:\n"
                "- Aumento en la incidencia de lesiones mÃºsculoesquelÃ©ticas.\n"
                "- AceleraciÃ³n en la apariciÃ³n de la fatiga.\n"
                "- DisminuciÃ³n de la eficiencia energÃ©tica y del rendimiento fÃ­sico.\n"
                "- Alteraciones en parÃ¡metros hormonales y metabÃ³licos.\n"
                "- Se recomienda realizar un seguimiento con un nutricionista deportivo."
            )
        else:
            return "Tu nivel de grasa corporal estÃ¡ en el rango ideal para un futbolista de alto rendimiento."
        
    
    return ""

def get_observacion_cmj(valor_cmj, categoria, gender):
    """
    Devuelve una frase interpretativa para el test de CMJ segÃºn la categorÃ­a ('Juvenil' o 'Cadete')
    y el valor de salto (en cm).
    """

    if valor_cmj is None or pd.isna(valor_cmj):
        return ""

    categoria = categoria.lower()

    if "juvenil" in categoria:
        if gender == "H":
            if valor_cmj > 36:
                return (
                    "Tu nivel en el CMJ estÃ¡ dentro del rango Ã³ptimo de rendimiento.\n"
                    "El objetivo es mejorar la eficiencia en la tÃ©cnica de salto y mantener o incrementar levemente el rendimiento."
                )
            elif 32 < valor_cmj <= 36:
                return (
                    "Mejorar la eficiencia en la tÃ©cnica de salto.\n"
                    "Necesidad de trabajo de potencia de tren inferior."
                )
            elif valor_cmj <= 32:
                return (
                    "Masa muscular insuficiente.\n"
                    "Necesidad de trabajo de fuerza y potencia de tren inferior.\n"
                    "Mejorar la tÃ©cnica de salto."
                )
        elif gender == "M":
            if valor_cmj >= 34:
                return (
                    "Excelente estado de potencia de miembro inferior para el fÃºtbol femenino"
                    )
            elif 24 < valor_cmj < 34:
                return (
                    "Tu nivel en el CMJ estÃ¡ dentro del rango Ã³ptimo de rendimiento.\n"
                    "El objetivo es mejorar la eficiencia en la tÃ©cnica de salto y mantener o incrementar levemente el rendimiento."
                )
            elif 23 <= valor_cmj < 24:
                return (
                    "Mejorar la eficiencia en la tÃ©cnica de salto.\n"
                    "Necesidad de trabajo de potencia de tren inferior."
                )
            elif valor_cmj <= 22:
                return (
                    "Masa muscular insuficiente.\n"
                    "Necesidad de trabajo de fuerza y potencia de tren inferior.\n"
                    "Mejorar la tÃ©cnica de salto."
                )
    elif "cadete" in categoria:
        if gender == "H":
            if valor_cmj > 30:
                return (
                    "Tu nivel en el CMJ estÃ¡ dentro del rango Ã³ptimo de rendimiento."
                )
            elif 26 < valor_cmj <= 30:
                return (
                    "Mejorar la eficiencia en la tÃ©cnica de salto.\n"
                    "Necesidad de trabajo de potencia de tren inferior."
                )
            elif valor_cmj <= 26:
                return (
                    "Masa muscular insuficiente.\n"
                    "Necesidad de trabajo de fuerza y potencia de tren inferior.\n"
                    "Mejorar la tÃ©cnica de salto."
                )
        elif gender == "M":
            if valor_cmj >= 31:
                return (
                    "Excelente estado de potencia de miembro inferior para el fÃºtbol femenino"
                    )
            elif 23 <= valor_cmj <= 30:
                return (
                    "Tu nivel en el CMJ estÃ¡ dentro del rango Ã³ptimo de rendimiento.\n"
                    "El objetivo es mejorar la eficiencia en la tÃ©cnica de salto y mantener o incrementar levemente el rendimiento."
                )
            elif 20 <= valor_cmj <= 22:
                return (
                    "Mejorar la eficiencia en la tÃ©cnica de salto.\n"
                    "Necesidad de trabajo de potencia de tren inferior."
                )
            elif valor_cmj <= 19:
                return (
                    "Masa muscular insuficiente.\n"
                    "Necesidad de trabajo de fuerza y potencia de tren inferior.\n"
                    "Mejorar la tÃ©cnica de salto."
                )
    return ""

def get_observacion_sprint(valor_sprint, categoria, genero):
    """
    Devuelve una observaciÃ³n interpretativa segÃºn el valor del sprint (0-40m en segundos),
    la categorÃ­a ('Juvenil' o 'Cadete') y el gÃ©nero ('H' o 'M').
    """

    if valor_sprint is None or pd.isna(valor_sprint):
        return ""

    categoria = categoria.lower()
    genero = genero.upper()

    texto_1 = "Tu nivel de fuerza horizontal para el sprint es excelente para tu edad y categorÃ­a."
    texto_2 = (
        "Necesidad de trabajo tÃ©cnico de zancada y frecuencia de paso.\n"
        "Identificar si el dÃ©ficit estÃ¡ en la aceleraciÃ³n inicial o en la fase de velocidad mÃ¡xima.\n"
        "Mejorar tu potencia en tramos cortos."
    )
    texto_3 = (
        "Tienes un margen muy grande de mejora en el trabajo de fuerza de tren inferior.\n"
        "Necesidad de trabajo tÃ©cnico de zancada y frecuencia de paso.\n"
        "Es fundamental mejorar tu potencia en tramos cortos y largos."
    )

    if genero == "H":
        if "juvenil" in categoria:
            if valor_sprint < 5.2:
                return texto_1
            elif 5.2 <= valor_sprint < 5.8:
                return texto_2
            else:
                return texto_3

        elif "cadete" in categoria:
            if valor_sprint < 5.9:
                return texto_1
            elif 5.9 <= valor_sprint < 6.2:
                return texto_2
            else:
                return texto_3

    elif genero == "M":
        if "juvenil" in categoria:
            if valor_sprint < 6.2:
                return texto_1
            elif 6.3 <= valor_sprint < 6.5:
                return texto_2
            else:
                return texto_3

        elif "cadete" in categoria:
            if valor_sprint < 6.4:
                return texto_1
            elif 6.5 <= valor_sprint < 6.7:
                return texto_2
            else:
                return texto_3

    return ""


def get_observacion_agilidad(valor_asimetria, genero="H", categoria="juvenil"):
    """
    Devuelve una observaciÃ³n interpretativa basada en el porcentaje de asimetrÃ­a funcional
    entre ambas piernas, considerando gÃ©nero y categorÃ­a.
    """
    if valor_asimetria is None or pd.isna(valor_asimetria):
        return ""

    genero = genero.upper()
    categoria = categoria.lower()
    
    if genero == "M":
        if categoria == "cadete":
            
            if valor_asimetria < 4:
                return "La jugadora presenta un nivel de simetrÃ­a funcional adecuado (< 4%) entre ambas piernas en el cambio de direcciÃ³n."
            elif valor_asimetria <= 6:
                return (
                    "Ligera asimetrÃ­a funcional entre ambas piernas en el cambio de direcciÃ³n.\n"
                    "Es recomendable aplicar estrategias preventivas para evitar que afecte el rendimiento o aumente el riesgo de lesiÃ³n."
                )
            else:
                return (
                    "AsimetrÃ­a >7% en el cambio de direcciÃ³n representa:\n- DÃ©ficit de fuerza excÃ©ntrica y/o potencia reactiva.\n- Necesidad de mejora de la tÃ©cnica de frenado.\n- Incremento en el riesgo de lesiÃ³n musculoesquelÃ©tica, sobre todo en isquiosurales y LCA.\n- LimitaciÃ³n de la capacidad de realizar acciones explosivas (con giros, fintas, driblings).\n\nRecomendamos un plan especÃ­fico de entrenamiento unilateral de la pierna deficitaria."
                )

        elif categoria == "juvenil":
            if valor_asimetria < 3:
                return "La jugadora presenta un nivel de simetrÃ­a funcional adecuado (< 3%) entre ambas piernas en el cambio de direcciÃ³n."
            elif valor_asimetria < 5.5:
                return (
                    "Ligera asimetrÃ­a funcional entre ambas piernas en el cambio de direcciÃ³n.\n"
                    "Es recomendable aplicar estrategias preventivas para evitar que afecte el rendimiento o aumente el riesgo de lesiÃ³n."
                )
            else:
                return (
                    "AsimetrÃ­a > 5.5% en el cambio de direcciÃ³n representa:\n- DÃ©ficit de fuerza excÃ©ntrica y/o potencia reactiva\n- Necesidad de mejora de la tÃ©cnica de frenado \n- Incremento en el riesgo de lesiÃ³n musculoesquelÃ©tica, sobre todo en isquiosurales y LCA.\n- LimitaciÃ³n de la capacidad de realizar acciones explosivas (con giros, fintas, driblings)\n\nRecomendamos un plan especÃ­fico de entrenamiento unilateral de la pierna deficitaria."
                )

    # Default masculino
    if valor_asimetria <= 5:
        return (
            "El jugador presenta un nivel de simetrÃ­a funcional adecuado (<5%) entre ambas piernas en el cambio de direcciÃ³n."
        )
    elif 5 < valor_asimetria <= 8:
        return (
            "Ligera asimetrÃ­a funcional entre ambas piernas en el cambio de direcciÃ³n.\n"
            "Aunque se encuentra dentro de un rango aceptable, es recomendable aplicar estrategias preventivas para evitar que esta diferencia aumente y afecte el rendimiento o aumente el riesgo de lesiÃ³n."
        )
    else:
        return (
            "AsimetrÃ­a >10% en el cambio de direcciÃ³n representa:\n"
            "- DÃ©ficit de fuerza excÃ©ntrica y/o potencia reactiva.\n"
            "- Necesidad de mejora de la tÃ©cnica de frenado.\n"
            "- Incremento en el riesgo de lesiÃ³n musculoesquelÃ©tica, sobre todo en isquiosurales y LCA.\n"
            "- LimitaciÃ³n de la capacidad de realizar acciones explosivas (con giros, fintas, driblings).\n\n"
            "Recomendamos un plan especÃ­fico de entrenamiento unilateral de la pierna deficitaria."
        )

